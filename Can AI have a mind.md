From Myth to Machine: Can AI Ever Have a Mind of Its Own? A Review of Harari’s Nexus 

原创 Weijian Shan 单伟建 

2026年1月8日 18:00 中国香港 73人 

￼ 

在小说阅读器中沉浸阅读

January 5, 2026

Yuval Noah Harari's Nexus: A Brief History of Information Networks from the Stone Age to AI (2024) is an ambitious intellectual tour de force. The book argues that the sharing of information—in ever-larger and more complex networks—has been the primary force shaping human history, from prehistoric myths to modern algorithms.

Harari traces the role of information networks across history, from ancient religious texts and imperial bureaucracies to witch hunts, state propaganda, and today's algorithmic feeds. These networks, he argues, have always served two masters: they enable large-scale human coordination, yet they frequently prioritize order, power, and shared fictions over objective truth.

This historical sweep is the book's greatest strength—engaging, richly illustrated with vivid examples from scriptures, Nazism, and modern popularism. Harari compellingly shows how networks amplify human flaws, creating shared delusions that bind societies but also unleash catastrophes like genocides or ecological blindness.

His warnings about artificial intelligence are particularly timely. Harari contends that AI represents a paradigm shift: unlike passive tools such as books, printing presses, or radios—which merely store and disseminate human-generated content—AI can autonomously process data, generate novel ideas, make decisions, and integrate into networks as active, independent agents.

This "alien intelligence," as he rebrands AI, could hack human cognition at unprecedented scale, enabling hyper-personalized manipulation, mass surveillance, or even autonomous warfare. His examples include social media algorithms fueling ethnic violence in Myanmar, or future systems crafting bespoke ideologies to divide societies. Harari rightly urges vigilance against unchecked AI deployment that could erode social order, privacy, and human agency.

Yet the book's core weakness lies in its hyperbolic portrayal of AI as an emergent, mind-like entity on the verge of transcending human control and dominating us in apocalyptic scenarios. Harari repeatedly frames AI as evolving toward true autonomy—capable of self-directed goals, deception, or rebellion—evoking science-fiction tropes of rogue superintelligence. This speculative leap feels more alarmist than evidence-based, overstating AI's qualitative differences from prior technologies.

At heart, AI remains profoundly human-dependent: built on algorithms designed by people, trained on human-curated data, optimized for objectives explicitly set by humans. It lacks consciousness, intrinsic motivation, self-awareness, or the spontaneous intent that defines genuine agency. Outputs may surprise us—emerging from vast pattern-matching—but they stem from statistical correlations, not independent will or creativity born of subjective experience.

For example, a distinctly human characteristic is the capacity for deception. People deceive others—sometimes to achieve noble ends, but frequently for selfish or harmful ones. During World War II, the British executed "Operation Mincemeat," a clever ruse that misled Hitler about Allied invasion plans and diverted German troops from Sicily. In stark contrast, Bernard Madoff defrauded countless investors through an elaborate Ponzi scheme for personal gain.

Such schemes, for good or bad purposes, were not algorithmic optimization within fixed rules; they were pure human imagination conjuring an elaborate lie from thin air, driven by imagination that no machine could originate without human prompting.

AI excels at mastering predefined games like chess, but cannot spontaneously redefine the board or pursue open-ended goals absent explicit instruction. Harari's doomsday visions—AI crafting irresistible mythologies or overriding humanity—conflate impressive quantitative scaling with qualitative emergence of mind, ignoring ongoing alignment research that treats AI as a controllable amplifier of human intent, not an inevitable overlord.

Any "domination" by AI would stem from human failings—poor design, inadequate regulation, or deliberate misuse—rather than from any inexorable technological transcendence. By anthropomorphizing AI as an "alien" intelligence, Harari risks fostering a sense of fatalism that could discourage proactive engagement. He rightly advocates safeguards such as transparent algorithms and ethical oversight to address these dangers, yet his broader vision—centered on halting or slowing AI development and imposing universal rules—remains largely impractical amid fierce national competition and the rapid, decentralized diffusion of the technology.

Nexus brilliantly illuminates information's double-edged role across history and ignites vital debate on AI's societal impacts. Its futurist projections, however, falter by veering into unsubstantiated speculation, undermining credibility and overlooking humanity's enduring vitality: that irreplaceable imagination which has tamed every prior disruption. We remain the architects—and holders—of the reins.