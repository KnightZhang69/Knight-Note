# Bilawal Sidhu and Eric Schmidt on TED: The AI Revolution is Underhyped - English and Chinese

## Transcript

**Bilawal Sidhu (BS):** Eric Schmidt, thank you for joining us.  
**毕拉瓦·西杜 (BS):** 埃里克·施密特，感谢您加入我们。  
Let’s go back.  
让我们回顾一下。  
You said the arrival of non-human intelligence is a very big deal.  
您说过，非人类智能的到来是一件非常重要的事情。  
And this photo, taken in 2016, feels like one of those quiet moments where the Earth shifted beneath us, but not everyone noticed.  
这张2016年拍摄的照片，感觉像是地球在我们脚下悄然改变的时刻，但并非所有人都注意到了。  
What did you see back then that the rest of us might have missed? *(00:25)*  
您当时看到了什么，是我们其他人可能错过的？ *(00:25)*

**Eric Schmidt (ES):** In 2016, we didn’t understand what was now going to happen, but we understood that these algorithms were new and powerful.  
**埃里克·施密特 (ES):** 在2016年，我们不完全理解接下来会发生什么，但我们知道这些算法是全新的且非常强大。  
What happened in this particular set of games was in roughly the second game, there was a new move invented by AI in a game that had been around for over 3,000 years that no one had ever seen. *(00:47)*  
在这组特定的比赛中，大约在第二局中，人工智能在一个已有超过3000年历史的游戏中发明了一种从未见过的全新走法。 *(00:47)*  
*Note: Go was likely invented between 3,000 and 4,000 years ago. [Learn more](https://en.wikipedia.org/wiki/Go_(game)).*  
*注：围棋可能在3000至4000年前发明。[了解更多](https://en.wikipedia.org/wiki/Go_(game))。*  
Technically, the way this occurred was that the system of AlphaGo was essentially organized to always maintain a greater than 50 percent chance of winning.  
从技术上讲，这是因为AlphaGo系统基本上被设计为始终保持超过50%的胜率。  
And so it calculated correctly this move, which was this great mystery among all of the Go players who are obviously insanely brilliant, mathematical and intuitive players.  
因此，它正确计算了这一走法，这在所有明显才华横溢、数学和直觉出众的围棋玩家中是一个巨大的谜团。  
The question that Henry, Craig Mundie and I started to discuss, right, is what does this mean?  
亨利、克雷格·蒙迪和我开始讨论的问题是，这意味着什么？  
How is it that our computers could come up with something that humans had never thought about?  
我们的计算机是如何想出人类从未考虑过的东西的？  
I mean, this is a game played by billions of people.  
我的意思是，这是一个数十亿人玩过的游戏。  
And that began the process that led to two books.  
这开启了一个过程，最终促成了两本书的出版。  
And I think, frankly, is the point at which the revolution really started. *(01:35)*  
坦白说，我认为这是革命真正开始的时刻。 *(01:35)*

**BS:** If you fast forward to today, it seems that all anyone can talk about is AI, especially here at TED.  
**BS:** 如果快进到今天，似乎所有人都在谈论人工智能，尤其是在TED这里。  
But you’ve taken a contrarian stance.  
但您采取了一种相反的立场。  
You actually think AI is underhyped.  
您实际上认为人工智能被低估了。  
Why is that? *(01:49)*  
为什么会这样？ *(01:49)*

**ES:** And I’ll tell you why.  
**ES:** 我来告诉你为什么。  
Most of you think of AI as, I’ll just use the general term, as ChatGPT.  
你们大多数人认为人工智能是，我用一个通用的术语，ChatGPT。  
For most of you, ChatGPT was the moment where you said, “Oh my God, this thing writes, and it makes mistakes, but it’s so brilliantly verbal.”  
对你们大多数人来说，ChatGPT是你们惊叹的时刻：“天哪，这东西会写字，会犯错，但它表达得如此出色。”  
That was certainly my reaction.  
这当然也是我的反应。  
Most people that I knew did that. *(02:07)*  
我认识的大多数人也是如此。 *(02:07)*

**BS:** It was visceral, yeah. *(02:08)*  
**BS:** 是的，感觉很直观。 *(02:08)*

**ES:** This was two years ago.  
**ES:** 那是两年前。  
Since then, the gains in what is called reinforcement learning, which is what AlphaGo helped advance and so forth, allow us to do planning.  
从那以后，所谓的强化学习取得了进展，AlphaGo推动了这一领域的发展，使我们能够进行规划。  
And a good example is look at OpenAI o3 or DeepSeek R1, and you can see how it goes forward and back, forward and back, forward and back.  
一个很好的例子是看看OpenAI的o3或DeepSeek的R1，你可以看到它如何来回迭代，前进后退，前进后退。  
It’s extraordinary.  
这太了不起了。  
In my case, I bought a rocket company because it was like, interesting. *(02:36)*  
就我而言，我买了一家火箭公司，因为它，嗯，很有趣。 *(02:36)*  
*Note: Reinforcement learning has been used in early artificial intelligence systems since at least the 1990s. [Learn more](https://en.wikipedia.org/wiki/Reinforcement_learning).*  
*注：强化学习至少自1990年代起就在早期人工智能系统中使用。[了解更多](https://en.wikipedia.org/wiki/Reinforcement_learning)。*  

**BS:** (Laughs) As one does. *(02:38)*  
**BS:** （笑）就像人们常做的那样。 *(02:38)*

**ES:** As one does.  
**ES:** 就像人们常做的那样。  
And it’s an area that I’m not an expert in, and I want to be an expert.  
这不是我擅长的领域，我想成为专家。  
So I’m using deep research.  
所以我在使用深度研究。  
And these systems are spending 15 minutes writing these deep papers.  
这些系统花15分钟就能写出这些深入的论文。  
That’s true for most of them.  
对大多数系统来说都是如此。  
Do you have any idea how much computation 15 minutes of these supercomputers is?  
你知道这些超级计算机15分钟的计算量有多大吗？  
It’s extraordinary.  
这太惊人了。  
So you’re seeing the arrival, the shift from language to language.  
所以你看到的是从语言到语言的转变。  
Then you had language to sequence, which is how biology is done.  
然后是从语言到序列，这是生物学的研究方式。  
Now you’re doing essentially planning and strategy.  
现在你基本上是在进行规划和战略。  
The eventual state of this is the computers running all business processes, right?  
最终状态是计算机运行所有业务流程，对吧？  
So you have an agent to do this, an agent to do this, an agent to do this.  
所以你有一个代理做这个，一个代理做那个，一个代理做另一个。  
And you concatenate them together, and they speak language among each other.  
你把它们串联起来，它们之间用语言交流。  
They typically speak English language. *(03:26)*  
它们通常使用英语。 *(03:26)*

**BS:** I mean, speaking of just the sheer compute requirements of these systems, let’s talk about scale briefly.  
**BS:** 我的意思是，谈到这些系统巨大的计算需求，我们来简单谈谈规模。  
You know, I kind of think of these AI systems as Hungry Hungry Hippos.  
你知道，我有点觉得这些人工智能系统像是《饿饿河马》游戏。  
They seemingly soak up all the data and compute that we throw at them.  
它们似乎吸收了我们提供的所有数据和计算能力。  
They’ve already digested all the tokens on the public internet, and it seems we can’t build data centers fast enough.  
它们已经消化了公共网络上的所有数据标记，似乎我们建数据中心的速度还不够快。  
What do you think the real limits are, and how do we get ahead of them before they start throttling AI progress? *(03:54)*  
您认为真正的限制是什么，我们如何在它们开始限制人工智能进步之前解决这些问题？ *(03:54)*

**ES:** So there’s a real limit in energy.  
**ES:** 所以能源是一个真正的限制。  
Give you an example.  
举个例子。  
There’s one calculation, and I testified on this this week in Congress, that we need another 90 gigawatts of power in America.  
有一个计算，我本周在国会作证时提到，美国需要额外90吉瓦的电力。  
My answer, by the way, is, think Canada, right?  
顺便说一句，我的回答是，想想加拿大，对吧？  
Nice people, full of hydroelectric power.  
那里的人很好，拥有大量水力发电。  
But that’s apparently not the political mood right now.  
但现在显然不是这种政治氛围。  
Sorry.  
抱歉。  
So 90 gigawatts is 90 nuclear power plants in America.  
所以90吉瓦在美国相当于90座核电站。  
Not happening.  
这是不可能的。  
We’re building zero, right?  
我们现在一座也没建，对吧？  
How are we going to get all that power?  
我们如何获得所有这些电力？  
This is a major, major national issue.  
这是一个重大的国家问题。  
You can use the Arab world, which is busy building five to 10 gigawatts of data centers.  
你可以利用阿拉伯世界，他们正在忙于建设5到10吉瓦的数据中心。  
India is considering a 10-gigawatt data center.  
印度正在考虑建设一个10吉瓦的数据中心。  
To understand how big gigawatts are, is think cities per data center.  
要理解吉瓦有多大，想想每个数据中心相当于一个城市。  
That’s how much power these things need. *(04:53)*  
这就是这些东西需要的电力。 *(04:53)*  
*Note: This estimate comes from a CSIS Economic Security and Technology Department report. [Read more](https://www.csis.org/analysis/powering-intelligence-energy-implications-artificial-intelligence).*  
*注：这一估计来自CSIS经济安全与技术部门报告。[了解更多](https://www.csis.org/analysis/powering-intelligence-energy-implications-artificial-intelligence)。*  
And the people look at it and they say, “Well, there’s lots of algorithmic improvements, and you will need less power.”  
人们看着它说：“嗯，有很多算法改进，你会需要更少的电力。”  
There’s an old rule, I’m old enough to remember, right?  
有一个老规矩，我年纪够大，记得，对吧？  
Grove giveth, Gates taketh away.  
格罗夫给予，盖茨拿走。  
OK, the hardware just gets faster and faster.  
好的，硬件变得越来越快。  
The physicists are amazing.  
物理学家们很了不起。  
Just incredible what they’ve been able to do.  
他们能做到的事情简直不可思议。  
And us software people, we just use it and use it and use it.  
而我们这些软件人，只是不断地使用它。  
And when you look at planning, at least in today’s algorithms, it’s back and forth and try this and that and just watch it yourself.  
当你看规划，至少在今天的算法中，它是来回尝试，试试这个，试试那个，你自己看看。  
There are estimates, and you know this from Andreessen Horowitz reports, it’s been well studied, that there’s an increase in at least a factor of 100, maybe a factor of 1,000, in computation required just to do the kind of planning.  
有估计，你从Andreessen Horowitz的报告中知道，这已被广泛研究，仅进行这种规划所需的计算量就增加了至少100倍，也许是1000倍。  
The technology goes from essentially deep learning to reinforcement learning to something called test-time compute, where not only are you doing planning, but you’re also learning while you’re doing planning.  
技术从基本上是深度学习发展到强化学习，再到所谓的测试时计算，不仅你在规划，还在规划时学习。  
That is the, if you will, the zenith or what have you, of computation needs.  
这可以说是计算需求的顶点。  
That’s problem number one, electricity and hardware. *(05:53)*  
这是第一个问题，电力和硬件。 *(05:53)*  
Problem number two is we ran out of data so we have to start generating it.  
第二个问题是我们用完了数据，所以我们必须开始生成数据。  
But we can easily do that because that’s one of the functions. *(06:01)*  
但我们可以轻松做到，因为这是其中一个功能。 *(06:01)*  
And then the third question that I don’t understand is what’s the limit of knowledge?  
然后我还不明白的第三个问题是知识的极限是什么？  
I’ll give you an example.  
我给你举个例子。  
Let’s imagine we are collectively all of the computers in the world, and we’re all thinking and we’re all thinking based on knowledge that exists that was previously invented.  
让我们想象我们是世界上所有的计算机，我们都在思考，而且我们思考的都是基于之前发明存在的知识。  
How do we invent something completely new?  
我们如何发明完全新的东西？  
So, Einstein.  
比如，爱因斯坦。  
So when you study the way scientific discovery works, biology, math, so forth and so on, what typically happens is a truly brilliant human being looks at one area and says, “I see a pattern that’s in a completely different area, has nothing to do with the first one. It’s the same pattern.”  
所以当你研究科学发现如何运作，生物学、数学等等，通常发生的是一个真正聪明的人看着一个领域说：“我看到一个完全不同领域的模式，与第一个领域无关。它是同一个模式。”  
And they take the tools from one and they apply it to another. *(06:45)*  
他们从一个领域拿来工具，应用到另一个领域。 *(06:45)*  
Today, our systems cannot do that.  
今天，我们的系统无法做到这一点。  
If we can get through that, I’m working on this, a general technical term for this is non-stationarity of objectives.  
如果我们能解决这个问题，我正在研究这个，这有一个通用的技术术语，叫做目标的非平稳性。  
The rules keep changing.  
规则一直在变化。  
We will see if we can solve that problem.  
我们会看看能否解决这个问题。  
If we can solve that, we’re going to need even more data centers.  
如果我们能解决这个问题，我们将需要更多的数据中心。  
And we’ll also be able to invent completely new schools of scientific and intellectual thought, which will be incredible. *(07:11)*  
我们还将能够发明全新的科学和知识思想流派，这将是不可思议的。 *(07:11)*

**BS:** So as we push towards a zenith, autonomy has been a big topic of discussion.  
**BS:** 所以当我们迈向顶点时，自主性一直是一个热门话题。  
Yoshua Bengio gave a compelling talk earlier this week, advocating that AI labs should halt the development of agentic AI systems that are capable of taking autonomous action.  
约书亚·本吉奥本周早些时候发表了一场引人入胜的演讲，主张人工智能实验室应停止开发能够自主行动的智能体系统。  
Yet that is precisely what the next frontier is for all these AI labs, and seemingly for yourself, too.  
然而，这正是所有这些人工智能实验室的下一个前沿，似乎对您也是如此。  
What is the right decision here? *(07:33)*  
这里的正确决定是什么？ *(07:33)*

**ES:** So Yoshua is a brilliant inventor of much of what we’re talking about and a good personal friend.  
**ES:** 约书亚是我们讨论内容的杰出发明家，也是我的好朋友。  
And we’ve talked about this, and his concerns are very legitimate.  
我们讨论过这个，他担忧是非常合理的。  
The question is not are his concerns right, but what are the solutions?  
问题不在于他的担忧是否正确，而在于解决方案是什么？  
So let’s think about agents.  
所以让我们来想想智能体。  
So for purposes of argument, everyone in the audience is an agent.  
为了讨论的目的，观众中的每个人都是一个智能体。  
You have an input that’s English or whatever language.  
你有一个输入，是英语或其他语言。  
And you have an output that’s English, and you have memory, which is true of all humans.  
你有一个输出是英语，你有记忆，这是所有人类的共同点。  
Now we’re all busy working, and all of a sudden, one of you decides it’s much more efficient not to use human language, but we’ll invent our own computer language.  
现在我们都在忙着工作，突然间，你们中的一个决定不使用人类语言更有效率，而是发明我们自己的计算机语言。  
Now you and I are sitting here, watching all of this, and we’re saying, like, what do we do now?  
现在你和我坐在这里，看着这一切，我们在说，现在该怎么办？  
The correct answer is unplug you, right?  
正确的答案是拔掉你的插头，对吧？  
Because we’re not going to know, we’re just not going to know what you’re up to.  
因为我们不会知道，我们完全不知道你在做什么。  
And you might actually be doing something really bad or really amazing.  
你可能在做非常坏或非常了不起的事情。  
We want to be able to watch.  
我们希望能够观察。  
So we need provenance, something you and I have talked about, but we also need to be able to observe it.  
所以我们需要来源证明，这是你我讨论过的事情，但我们也需要能够观察它。  
To me, that’s a core requirement. *(08:42)*  
对我来说，这是一个核心要求。 *(08:42)*  
There’s a set of criteria that the industry believes are points where you want to, metaphorically, unplug it.  
行业认为有一些标准是你希望，形象地说，拔掉插头的点。  
One is where you get recursive self-improvement, which you can’t control.  
一个是你得到无法控制的递归自我改进。  
Recursive self-improvement is where the computer is off learning, and you don’t know what it’s learning.  
递归自我改进是计算机在自行学习，而你不知道它在学什么。  
That can obviously lead to bad outcomes.  
这显然可能导致不良后果。  
Another one would be direct access to weapons.  
另一个是直接接触武器。  
Another one would be that the computer systems decide to exfiltrate themselves, to reproduce themselves without our permission.  
还有一个是计算机系统决定自行渗透，擅自复制自己。  
So there’s a set of such things. *(09:06)*  
所以有一系列这样的事情。 *(09:06)*  
The problem with Yoshua’s speech, with respect to such a brilliant person, is stopping things in a globally competitive market doesn’t really work.  
约书亚的演讲的问题，尽管他如此杰出，是在全球竞争市场中停止事情并不实际。  
Instead of stopping agentic work, we need to find a way to establish the guardrails, which I know you agree with because we’ve talked about it. *(09:26)*  
与其停止智能体工作，我们需要找到一种建立护栏的方法，我知道你同意，因为我们讨论过这个。 *(09:26)*

**BS:** I think that brings us nicely to the dilemmas.  
**BS:** 我认为这很好地带我们进入了困境。  
And let’s just say there are a lot of them when it comes to this technology.  
可以说，涉及这项技术有很多困境。  
The first one I’d love to start with, Eric, is the exceedingly dual-use nature of this tech, right?  
我想开始的第一个，埃里克，是这项技术的极端双重用途，对吧？  
It’s applicable to both civilian and military applications.  
它适用于民用和军事应用。  
So how do you broadly think about the dilemmas and ethical quandaries that come with this tech and how humans deploy them? *(09:53)*  
那么，您如何广泛思考这项技术带来的困境和伦理难题，以及人类如何部署它们？ *(09:53)*

**ES:** In many cases, we already have doctrines about personal responsibility.  
**ES:** 在许多情况下，我们已经有了关于个人责任的准则。  
A simple example, I did a lot of military work and continue to do so.  
一个简单的例子，我做过很多军事工作，现在还在继续。  
The US military has a rule called 3000