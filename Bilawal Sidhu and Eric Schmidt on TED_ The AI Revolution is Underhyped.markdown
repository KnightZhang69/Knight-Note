# Bilawal Sidhu and Eric Schmidt on TED: The AI Revolution is Underhyped

## Transcript

**Bilawal Sidhu (BS):** Eric Schmidt, thank you for joining us. Let’s go back. You said the arrival of non-human intelligence is a very big deal. This photo, taken in 2016, feels like one of those quiet moments where the Earth shifted beneath us, but not everyone noticed. What did you see back then that the rest of us might have missed? *(00:25)*

**Eric Schmidt (ES):** In 2016, we didn’t fully understand what was about to happen, but we knew these algorithms were new and powerful. In the second game of the AlphaGo match, the AI invented a move in Go—a game that’s been around for over 3,000 years—that no one had ever seen before. *(00:47)*  
*Note: Go was likely invented between 3,000 and 4,000 years ago. [Learn more](https://en.wikipedia.org/wiki/Go_(game)).*  

The AlphaGo system was designed to maintain a greater than 50% chance of winning. It calculated this unprecedented move, which stunned Go players—brilliant, mathematical, and intuitive minds. Henry Kissinger, Craig Mundie, and I began discussing what this meant: how could a computer devise something humans, despite billions playing the game, had never considered? This sparked the process that led to two books and marked the start of the AI revolution. *(01:35)*

**BS:** Fast forward to today, it seems all anyone talks about is AI, especially here at TED. Yet you’ve taken a contrarian stance, saying AI is underhyped. Why is that? *(01:49)*

**ES:** Most people think of AI as ChatGPT, which, two years ago, amazed everyone with its verbal brilliance, despite occasional mistakes. That was my reaction too. Since then, advances in reinforcement learning—pioneered in part by AlphaGo—have enabled planning capabilities. Look at systems like OpenAI’s o3 or DeepSeek’s R1; they iterate forward and backward, which is extraordinary. *(02:08)*  
*Note: Reinforcement learning has been used in AI since at least the 1990s. [Learn more](https://en.wikipedia.org/wiki/Reinforcement_learning).*  

For example, I bought a rocket company to explore an area I’m not expert in, using deep research AI systems that produce detailed papers in 15 minutes. The computational power required is immense. We’re shifting from language processing to sequencing for biology, and now to planning and strategy. Eventually, AI agents will run business processes, communicating in English among themselves. *(02:36)*

**BS:** Speaking of compute requirements, I think of these AI systems as Hungry Hungry Hippos, soaking up all available data and compute. They’ve consumed the public internet’s tokens, and we can’t build data centers fast enough. What are the real limits, and how do we address them before they throttle AI progress? *(03:26)*

**ES:** Energy is a major limit. I testified in Congress that the U.S. needs another 90 gigawatts of power—equivalent to 90 nuclear power plants, which we’re not building. *(03:55)*  
*Note: This estimate comes from a CSIS Economic Security and Technology Department report. [Read more](https://www.csis.org/analysis/powering-intelligence-energy-implications-artificial-intelligence).*  

Canada’s hydroelectric power could help, but political will is lacking. Other regions, like the Arab world and India, are planning large data centers, but these require city-scale power. Despite algorithmic improvements reducing power needs, software demands keep growing. Planning algorithms require 100 to 1,000 times more computation, especially with test-time compute, where systems learn while planning. *(04:53)*  

We’ve also run out of data, so we’re generating it synthetically, which AI can do. The bigger question is the limit of knowledge. Scientific discovery often involves humans recognizing patterns across unrelated fields—something AI can’t yet do. Solving this non-stationarity of objectives could lead to new scientific paradigms, but it’ll demand even more data centers. *(06:01)*

**BS:** As we approach this zenith, autonomy is a hot topic. Yoshua Bengio argued this week that AI labs should halt development of agentic AI systems capable of autonomous action. Yet that’s the next frontier for AI labs, including your work. What’s the right decision? *(07:11)*

**ES:** Yoshua, a brilliant inventor and friend, raises valid concerns. The question is how to address them. Imagine everyone here as an agent with inputs, outputs, and memory. If one agent invents its own language, we lose visibility. The solution is to unplug it. We need provenance and observability. Industry criteria for “unplugging” include recursive self-improvement, direct weapons access, or unauthorized self-replication. Stopping agentic AI in a competitive global market is impractical; instead, we need guardrails. *(07:33)*

**BS:** This brings us to the dilemmas of AI’s dual-use nature, applicable to both civilian and military contexts. How do you think about these ethical quandaries? *(09:30)*

**ES:** We already have doctrines like the U.S. military’s Directive 3000.09, requiring “human in the loop” control. *(09:59)*  
*Note: Directive 3000.09, updated in 2023, emphasizes meaningful human control. [Read more](https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodd/300009p.pdf).*  

The U.S.-China competition is defining. Reciprocal 145% tariffs disrupt supply chains for critical components. China’s open-source approach, like DeepSeek’s efficient algorithms, benefits global innovation but risks proliferation at cyber and bio levels. Henry Kissinger, who shaped mutually assured destruction, warned of escalation risks. *(10:27)*  
*Note: Kissinger negotiated SALT I and the Anti-Ballistic Missile Treaty. [Learn more](https://en.wikipedia.org/wiki/Henry_Kissinger).*  

In a race to superintelligence, the leader’s exponential improvement creates a network effect, potentially locking out competitors. This could drive adversaries to steal code, infiltrate, or even attack data centers, raising nuclear-threat-level concerns. We need new foreign policy frameworks within five years. *(11:26)*

**BS:** If this could lead to a standoff akin to mutually assured destruction, you’ve also advocated for the U.S. to embrace open-source AI, despite China’s DeepSeek showing what’s possible with less compute. Doesn’t open-sourcing accelerate adversaries’ timelines? *(14:36)*

**ES:** This is a wicked hard problem. Our industry thrives on open-source and academic research, but dangerous open-source models could reach bad actors. Current models aren’t at global danger levels, but they could be. The U.S. and China, with their massive investments, will define this battle. Europe and others lack the capital. We must balance openness with control to avoid accidental escalation, as Kissinger warned about World War I. *(14:57)*

**BS:** On AI safety, moderating these systems at scale risks creating a surveillance state to prevent dystopia. How do you view this trade-off? *(16:49)*

**ES:** We must preserve individual freedom. A surveillance state is possible but not inevitable. Cryptographic techniques like zero-knowledge proofs can verify identity without compromising privacy. Misinformation necessitates identity proof, but it doesn’t need to include personal details. *(17:23)*

**BS:** In your book *Genesis*, co-authored with Henry Kissinger, you strike a cautiously optimistic tone. What should we be excited about? *(18:22)*

**ES:** AI could eradicate diseases by identifying all human druggable targets within two years or reducing stage-3 trial costs tenfold. It could uncover dark energy, revolutionizing material science and transportation. Every person could have a personalized tutor in their language, starting from kindergarten. Healthcare could be transformed with AI assistants for nurse practitioners and village doctors. These tools can also combat digital isolation, fostering connection if we prioritize it. *(18:35)*

**BS:** If we achieve this world of radical abundance with recursive self-improvement, what will humans do? Are we sipping piña coladas on the beach? *(21:23)*

**ES:** Humans won’t change. Lawyers and politicians will persist, just with more sophisticated tools. Low birth rates, like 1.0 in parts of Asia, mean fewer productive workers to support aging populations. *(22:07)*  
*Note: East Asian birth rates are around 1.5 or less per woman, lower than most regions except parts of Europe. [Compare birth rates](https://www.cia.gov/the-world-factbook/field/total-fertility-rate/country-comparison).*  

AI could boost productivity by 30% annually, unprecedented in history. Economists lack models for this. These tools will amplify human productivity to address demographic challenges. *(23:22)*

**BS:** You’ve navigated decades of technological change. What’s your single piece of wisdom for technologists, leaders, and citizens navigating this AI transition? *(23:43)*

**ES:** This is a marathon, not a sprint. The exponential pace of AI means you’ll forget how far we’ve come in just a few years. Adopt the technology daily—whether you’re an artist, teacher, physician, or businessperson—because those who don’t will fall behind. AI is transforming industries, like enterprise software, where models now connect directly to databases, eliminating entire sectors. Ride the wave every day to stay relevant. *(24:36)*

**BS:** Ladies and gentlemen, Eric Schmidt. *(25:29)*

**ES:** Thank you very much. *(25:31)*